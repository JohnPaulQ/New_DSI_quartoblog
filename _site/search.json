[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSI",
    "section": "",
    "text": "The Data Science Initiative (DSI) at Chico State is a fledgling grassroots program, initiated in 2015 to develop the Data Science capabilities of our campus and community. By levering expertise across a wealth of disciplines including Statistics, Computer Science, Business, Biology, Nutrition, Mathematics and Political Science, Chico State is well poised to become an educational and workforce training leader in the North State.\nOur vision is to foster a data-empowered society working within a culture of open science."
  },
  {
    "objectID": "index.html#our-mission-is-to",
    "href": "index.html#our-mission-is-to",
    "title": "DSI",
    "section": "Our mission is to",
    "text": "Our mission is to\nFoster a supportive, inclusive and diverse community for data science researchers, practitioners, learners and enthusiasts.\nProvide high quality data science education to learners from all backgrounds and domains.\nDevelop and support interdisciplinary teaching and research opportunities\nEmphasize the use of data in an accountable and transparent manner for the benefit of all persons.\nFurthering the advancement of the algorithms and scientific methods to make decisions and extract insights from data."
  },
  {
    "objectID": "index.html#we-work-to-achieve-this-mission-by",
    "href": "index.html#we-work-to-achieve-this-mission-by",
    "title": "DSI",
    "section": "We work to achieve this mission by",
    "text": "We work to achieve this mission by\nBuilding relationships with community partners to build data enabled solutions and provide high impact real world learning experiences for students.\nProvide training on data privacy and security, responsible and ethical research, responsible, transparent and ethical uses of data and algorithms.\nProvide learners with the skills and knowledge, and build and confidence to develop and implement data-driven solutions in an ethically and socially responsible manner.\nUsing multiple methods of training including\nTraditional classroom and online curriculum\nWorkshops & specialized trainings\nInterdisciplinary projects that engage learners from diverse sectors\nBeing a campus wide resource through Community Coding - an open work and support session."
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News/Events",
    "section": "",
    "text": "Health Equity Datathon\n\n\n\n\n\n\n\nevent\n\n\n\n\n\n\n\n\n\n\n\nMar 9, 2023\n\n\n\n\n\n\n  \n\n\n\n\nDataFest 2023 April 14-16- Registration now open!\n\n\n\n\n\n\n\nevent\n\n\n\n\n\n\n\n\n\n\n\nMar 3, 2023\n\n\nDr. D\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResearch Statistician vacancies at the Bureau of Labor Statistics\n\n\n\n\n\n\n\nstatistics\n\n\nmathematics\n\n\nresearch\n\n\n\n\n\n\n\n\n\n\n\nNov 27, 2022\n\n\nDr. D\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Tech Justice: The Just Data Lab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 27, 2022\n\n\nMath 485 Student\n\n\n\n\n\n\n  \n\n\n\n\nFooling Facial Recognition\n\n\n\n\n\n\n\nmachine-learning\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\nBrandon Trahams\n\n\n\n\n\n\n  \n\n\n\n\nSeptember Student post: Introduction to SQL\n\n\n\n\n\n\n\ntutorial\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\nJoseph Shifman\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAugust Student post: Underlying geometry of data\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2022\n\n\nSkip Moses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFall 22 Guest post series\n\n\n\n\n\n\n\nlearning\n\n\n\n\n\n\n\n\n\n\n\nJul 17, 2022\n\n\nDr. D\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChico State Data Fest 2022 Recap\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApr 4, 2022\n\n\nFaith F.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew grant program supports Hispanic students in Data Science enabled USDA career paths.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2022\n\n\nFaith F.\n\n\n\n\n\n\n  \n\n\n\n\nUsing Data to Fight Food Insecurity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2021\n\n\nDr. D.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-09-23-fall-data-challenge/index.en.html",
    "href": "posts/2021-09-23-fall-data-challenge/index.en.html",
    "title": "Using Data to Fight Food Insecurity",
    "section": "",
    "text": "The Fall Data Challenge (https://thisisstatistics.org/falldatachallenge/) starts next Monday on October 11th. This is a GREAT opportunity for students to\n\napply statistical and data wrangling skills to important real-world issues and make recommendations to combat this critical issue\ncompete for prizes, T-shirts & bragging rights\nPractice for DataFest in the Spring!\n\nThis is a team event open to all majors. We welcome pre-formed teams as well as individuals! There will be a kickoff event Monday 10/11 night where teams can be formed. Late joins are also welcome!\nPlease see attached flier for more information. If you are interested, please contact Robin Donatello at rdonatello@csuchico.edu."
  },
  {
    "objectID": "posts/2022-03-01-project-da-fanh/index.en.html",
    "href": "posts/2022-03-01-project-da-fanh/index.en.html",
    "title": "New grant program supports Hispanic students in Data Science enabled USDA career paths.",
    "section": "",
    "text": "CHICO, Calif.- California State University, Chico and California State University, San Bernardino campuses partnered to better the education of Hispanic undergraduate students in food, agriculture, natural resources and human sciences domains (FANH).\nThe primary goal of this project is to retain and graduate highly qualified students in the intersection of data science (DS) and analytics (DA) and the food, agriculture, natural resources and human sciences domains. Project DA-FANH assists underserved students on both campuses and allows for increased representation in fields that are traditionally lacking in diversity. The program assists in training students how to use data to enhance the nation’s professional and scientific workforce.\nRobin Donatello, project director, explained the value of the program.\n\n“It showcases how data analytics is accessible to everyone, and it empowers students to learn how to be the boss of their own data and use it to make an impact in the societal areas they care about,” Donatello said.\n\nBy incorporating culturally relevant education while modeling data science and analytics techniques in the FANH curriculum, this project dismantles barriers and existing stereotypes about who belongs, and it builds a career pathway for students of color in the intersection of data science and analytics and FANH careers.\nProject activities include career panels and job assistance to provide students access to career opportunities. The project also offers internship experiences that emphasize problem solving, data-driven decision-making and remote team-collaboration skills.\nDA-FANH is directed by Robin Donatello (Chico State) and Essia Hamouda (Cal State San Bernardino) and is supported by many other influential and successful women, including specialty leads Stephanie Bianco and Christine Hererra. This partnership ignited a project that launched in August 2021 and was officially released February 21, 2022.\nFaculty-led project directors encourage and ensure that DS/DA skills are a part of a curriculum that supports FANH programs. All news, activities and latest updates will be accessible through the project website, along with social media links and scholarship opportunities.\nFor more information please visit the Project DA-FANH website or contact one of the project directors below:\nRobin Donatello DA-FANH Project Director Associate Professor in Statistics, California State University, Chico rdonatello@csuchico.edu\nEssia Hamouda DA-FANH Project Director Assistant Professor of Information and Decision Sciences California State University, San Bernardino ehamouda@csusb.edu"
  },
  {
    "objectID": "posts/2022-04-04-chico-state-data-fest-2022-recap.html",
    "href": "posts/2022-04-04-chico-state-data-fest-2022-recap.html",
    "title": "Chico State Data Fest 2022 Recap",
    "section": "",
    "text": "On April 1-3rd, Chico State University hosted the ASA DataFest 2022. DataFest is an event hosted by the Chico State Data Initiative (DSI), organized by Doctor Robin Donatello. Students were presented with undisclosed data on Friday and then worked through the weekend to gain the best insights into the confidential, real-world data sets. After long nights and early mornings, teams presented their findings to the experienced panel of judges for a chance at prizes and certificates. The event is part of the university’s efforts to provide training, expand collaboration and encourage new research in the field of Data Science and Data Analytics.\nKick-off began at 5:30 p.m. on Friday, April 1st, when teams from both Sacramento State and Chico State arrived to unravel their first data sets. 29 students made up the six different teams, with majors from all across the board. This year we had representation from Engineering (6.8%), Statistics (17%), Mathematics (13.7%), Computer Science (51.7%), Natural Sciences (Biology) (3.4%), Social Sciences (3.4%) and Business Information Systems (3.4%). The contestants’ experience in programming varied greatly, with some who were very well-versed and others who were just beginners.\nBy Sunday, the teams began wrapping up their findings and preparing for presentations, which were limited to five minutes each. Our panel of judges included: Stewart He, Data Scientist at Lawrence Livermore National Lab; Monica So, Assistant Professor at Chico State University; Kevin Buffardi, Faculty; and Christine Leistner, Faculty.\nEach team displayed great teamwork and demonstrated how working together can help you in the long run. With that said, the hardwork and dedication each team showed us reflected very heavily on this year’s winners. The winning teams of this year’s DataFest were:\n\nBest Analysis: K-Wildcat\nBest Discovery: K-Wildcat\nBest Visualization: Team Money\nJudge’s Choice: Lambda\n\nAcknowledgements\nIn addition to all the data exploration that took place throughout the weekend, we would like to give a special thank you to our sponsors: Chico State Data Science Initiative, American Statistical Association, ChicostArt, Center for Entrepreneurship at Chico State University, CSU Chico College of Business, Payless Building Supply, Math Club, and Stoble Coffee Roasters. Without the help of these amazing businesses and organizations, none of this would be possible.\nLastly, we would like to take this opportunity to acknowledge everyone who took the time to help build DataFest from the ground up. Support for the Data Science Initiative at Chico State by departments, organizations, and businesses like these are what make events for students possible.\nFollowing this year’s DataFest, the DSI is already looking to plan next year’s DataFest and looks forward to exposing more students to real world data issues. If you would like to be directly involved in next year’s festivities, please contact Robin Donatello at rdonatello@csuchico.edu."
  },
  {
    "objectID": "posts/2022-07-17-fall-22-guest-post-series/index.en.html",
    "href": "posts/2022-07-17-fall-22-guest-post-series/index.en.html",
    "title": "Fall 22 Guest post series",
    "section": "",
    "text": "Last Spring 2022 our most recent cohort of Data Science certificate students took the Advanced Data Science course, MATH/CSCI 485. In addition to consulting with campus based partners to use data science tools to solve a business or programmatic need, students practiced writing for a public audience.\nThis fall we will be showcasing these students contributed blog posts, one a month starting in August.\nTopic were chosen by the students based on their interest and range from theoretical examinations of graph data structure, to reflections on justice in tech, and tutorials on SQL.\nWe hope you enjoy these contributed posts!\nCheck out our homepage for up to date news on what’s happening in the world of Data Science at Chico State"
  },
  {
    "objectID": "posts/2022-08-01-guest-post-underlying-geometry-of-data/index.en.html",
    "href": "posts/2022-08-01-guest-post-underlying-geometry-of-data/index.en.html",
    "title": "August Student post: Underlying geometry of data",
    "section": "",
    "text": "We start our student contributed guest post series with a look at data from a topological lens. Skip Moses graduated from Chico State Department of Mathematics and Statistics in 2022. He triple majored in Pure Math, Applied Math, Statistics, and completed the Certificate in Data Science.\n\nData often has an underlying structure or geometry that can be modeled as a signal on the vertices of a weighted, undirected graph. Dong et. al. provide an algorithm for learning the underlying structure of a graph given a smooth signal representation on the graph here. Dong et. al. originally implemented the algorithm in MATLAB, however, it can be solved effiecently in Python. In the post here a brief description of the algorithm, and example of a learned graph are provided."
  },
  {
    "objectID": "posts/2022-09-01-student-post-intro-sql/index.en.html",
    "href": "posts/2022-09-01-student-post-intro-sql/index.en.html",
    "title": "September Student post: Introduction to SQL",
    "section": "",
    "text": "This is a quick-and-dirty introduction that will explain what SQL is, how it is used, and what some SQL queries look like in R using the dplyr package. SQL (sometimes pronounced “sequel”) stands for Structured Query Language. It is a programming language used to manipulate data in Relational Database Management Systems and it “is one of the most common languages for interacting with data” (source sqltutorial.org). SQL consists of three main languages under the same umbrella:\nThough SQL has a specific set of standards written by the American Standards Institute (ANSI), the user base constantly requires new features and capabilities. To accommodate this, there are a few different SQL “dialects” created by companies such as Oracle and Microsoft each with different syntaxes. In this tutorial, all SQL syntax used will be valid across all database systems.\nBefore going into SQL code, there are some important terms to know before creating a database. A primary key is a column or set of columns in a table whose value is unique for every record in the table. This can often be as simple as an integer ID or the combination of an ID and a date. A foreign key is a column in the table that refers to the primary key of another table. An example of this could be a situation where there is a table for purchases with a column for item number. The item number column is a foreign key that refers to the primary key item number of an items table with product information. For a more in-depth tutorial, I suggest reading through the Programiz tutorial."
  },
  {
    "objectID": "posts/2022-09-01-student-post-intro-sql/index.en.html#building-a-database-in-sql",
    "href": "posts/2022-09-01-student-post-intro-sql/index.en.html#building-a-database-in-sql",
    "title": "September Student post: Introduction to SQL",
    "section": "Building a database in SQL",
    "text": "Building a database in SQL\nBuilding a database requires a schema. This shows the organization of the data as a blueprint of how the database is constructed. Below is an example of a simple relational database schema with seven tables: \n(image source)\nThe above schema is actually incomplete as only primary keys are identified (with an *) and we are left to assume that foreign keys have the same column name as the primary key it refers to. For example, job_id in the employees table is a foreign key for the job_id primary key in the jobs table. The “crows feet” notation connecting each table defines how many of each record there is for each relationship. They aren’t as important when using SQL, but they are necessary knowledge when one has to interact with a real database. I’ll explain the relationship between employees and jobs as an example. The connector on the jobs table signifies that every employee has one and only one job_id reference to a job in the jobs table. The connector on the employees table means every job_id may be associated with zero or more records (people) in the employees table."
  },
  {
    "objectID": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-definition-language",
    "href": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-definition-language",
    "title": "September Student post: Introduction to SQL",
    "section": "Data Definition Language",
    "text": "Data Definition Language\nIn the industry, these commands are often restricted to be used by only the Database Management group. This is so that no random person in the company can edit the database and potentially destroy sensitive information. To show examples of database creation using SQL, I will create the jobs table. The following code chunk contains comments with more details:\n-- The notation at the start of this line denotes a comment, everything after \"--\" will be ignored\n-- All SQL commands must end in a semicolon \";\"\n-- Most SQL command words are in all caps, but this can depend on the system\n-- First we have to create the database, this one will be called \"HR\"\nCREATE DATABASE HR;\n\n-- The CREATE TABLE command creates a table and takes the columns with data types as the argument\n-- The basic syntax looks like this:\nCREATE TABLE table_name (\n  column1 datatype,\n  column2 datatype,\n  ...\n);\n\n-- Here is the full code to create the jobs table:\nCREATE TABLE jobs (\n    job_id INT (11) AUTO_INCREMENT PRIMARY KEY,\n    job_title VARCHAR (35) NOT NULL,\n    min_salary DECIMAL (8, 2) DEFAULT NULL,\n    max_salary DECIMAL (8, 2) DEFAULT NULL\n);\nIn the above code chunk, there were some new commands that may not look familiar. I’ll explain each column line-by-line.\n\nThe job_id column will be integer data. The number in parentheses tells the database the maximum number of digits that a job_id can have, in this case it is 11. The AUTO_INCREMENT command is an automatic function that runs whenever a new job is added to the table. Finally, PRIMARY KEY tells us this is the primary key.\nThe job_title column has a datatype called VARCHAR. This is a keyword meaning character data that is varying, essentially it is string data. The maximum length of a job_title is 35 characters, and the row cannot be empty. The NOT NULL command forces all records to have a job_title.\nThe last two columns, min_salary and max_salary, are very similar. They both have decimal data type, with 8 digits before the decimal and 2 digits after. Also, they both have DEFAULT NULL commands meaning that they are not required values when adding a new job. Adding a new job without specifying salaries will make those attributes empty.\n\nTo denote a foreign key, the structure looks like this:\nCREATE TABLE table_name (\n  column1 datatype,\n  column2 datatype,\n  ...\n  -- column3 is a primary key in another table\n  FOREIGN KEY (column2) REFERENCES another_table_name (column3)\n);\nAdditional commands are necessary to add to CREATE TABLE for when a table or record is deleted, but those are beyond the scope of this introduction. Other commands in the Data Definition language are shown below:\n-- See how these commands are not enclosed in parentheses?\n-- Little syntax differences like these can depend on the specific software being used\n-- However, all SQL commands end with a semicolon ;\n\nALTER TABLE table_name\nADD new_column datatype\nDROP old_column\nRENAME TO NEW_TABLE_NAME;\n\nDROP TABLE table_name;\n\n-- The ALTER TABLE command can also change column names and data definitions with RENAME and MODIFY"
  },
  {
    "objectID": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-control-language",
    "href": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-control-language",
    "title": "September Student post: Introduction to SQL",
    "section": "Data Control Language",
    "text": "Data Control Language\nThere are only two main commands in this language. They are GRANT and REVOKE. Only Database Administrator’s or owner’s of the database object can provide/remove privileges on a database object. The details of these commands are beyond the scope of this introduction, but their skeleton will be shown.\nThe syntax for the GRANT command is:\nGRANT privilege_name \nON database_name \nTO {user_name |PUBLIC |role_name} -- username or all users or users with role_name\n[WITH GRANT OPTION]; -- optional\nThe syntax for the REVOKE command is:\nREVOKE privilege_name \nON database_name \nFROM {user_name |PUBLIC |role_name}; -- username or all users or users with role_name"
  },
  {
    "objectID": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-manipulation-language",
    "href": "posts/2022-09-01-student-post-intro-sql/index.en.html#data-manipulation-language",
    "title": "September Student post: Introduction to SQL",
    "section": "Data Manipulation Language",
    "text": "Data Manipulation Language\nTo demonstrate examples, I will create a couple of toy datasets: one for employees and one for jobs. In these examples, I did not include a primary key for employees so we can assume the first and last name together are the primary key. The primary key of the jobs table is job_id and the employees table has a foreign key with the same name.\nemployees <- tibble(\n  first_name = c(\"Curly\", \"Larry\", \"Moe\", \"Joe\"),\n  last_name = c(\"Morris\", \"Cambridge\", \"Wallace\", \"Frasier\"),\n  salary = c(10000.00, 10000.00, 12500.00, 13333.33),\n  job_id = c(1, 2, 3, 4)\n)\nhead(employees)\n## # A tibble: 4 × 4\n##   first_name last_name salary job_id\n##   <chr>      <chr>      <dbl>  <dbl>\n## 1 Curly      Morris    10000       1\n## 2 Larry      Cambridge 10000       2\n## 3 Moe        Wallace   12500       3\n## 4 Joe        Frasier   13333.      4\njobs <- tibble(\n  job_title = c(\"Janitor\", \"Maintenenace\", \"Electrical\", \"Manager\"),\n  job_id = c(1, 2, 3, 4)\n)\nhead(jobs)\n## # A tibble: 4 × 2\n##   job_title    job_id\n##   <chr>         <dbl>\n## 1 Janitor           1\n## 2 Maintenenace      2\n## 3 Electrical        3\n## 4 Manager           4\nFor this introduction, I’ll focus on the SELECT command to make queries to the database. However, there are other commands in the language such as INSERT, UPDATE, and DELETE. The basic format of a SQL query looks like this:\nSELECT select_list\nFROM table_name;\nUsing R, this command would look like:\nselect(data = table_name, column1, column2, ...)\nThe select list can be any number of comma-separated column names or an asterisk * to denote all columns in the table. When evaluating the SELECT statement, the database system evaluates the FROM clause first and then the SELECT clause. You can also do arithmetic in the SELECT clause, a couple of examples are below with their R translation and output:\nSELECT first_name, last_name, salary, salary * 1.25\nFROM employees;\nemployees %>% select(first_name, last_name, salary) %>%\n  mutate(raise = salary * 1.25)\n## # A tibble: 4 × 4\n##   first_name last_name salary  raise\n##   <chr>      <chr>      <dbl>  <dbl>\n## 1 Curly      Morris    10000  12500 \n## 2 Larry      Cambridge 10000  12500 \n## 3 Moe        Wallace   12500  15625 \n## 4 Joe        Frasier   13333. 16667.\nSELECT AVG(salary), COUNT(DISTINCT(salary)), ROUND(salary, 0) -- round to 0 decimal places\nFROM employees;\nemployees %>% transmute(avg_salary = mean(salary),\n          count_distinct = n_distinct(salary), trunc_salary = floor(salary))\n## # A tibble: 4 × 3\n##   avg_salary count_distinct trunc_salary\n##        <dbl>          <int>        <dbl>\n## 1     11458.              3        10000\n## 2     11458.              3        10000\n## 3     11458.              3        12500\n## 4     11458.              3        13333\nSELECT MAX(salary), MIN(salary)\nFROM employees;\nemployees %>% transmute(max_sal = max(salary), min_sal = min(salary))\n## # A tibble: 4 × 2\n##   max_sal min_sal\n##     <dbl>   <dbl>\n## 1  13333.   10000\n## 2  13333.   10000\n## 3  13333.   10000\n## 4  13333.   10000\nTo get data from other tables and join it to this one, we use a JOIN clause. Using INNER JOIN, we can select the rows that have a record in both tables. SQL also supports LEFT JOIN and RIGHT JOIN. The format looks like this:\nSELECT first_name, last_name, job_title\nFROM employees\nINNER JOIN jobs ON job_id = job_id;\n-- the name before the equals sign is the primary key in the employees table\nIn R, it might look like this:\nemployees %>% select(first_name, last_name, job_id) %>%\n  inner_join(jobs, by=c(\"job_id\"=\"job_id\"))\n## # A tibble: 4 × 4\n##   first_name last_name job_id job_title   \n##   <chr>      <chr>      <dbl> <chr>       \n## 1 Curly      Morris         1 Janitor     \n## 2 Larry      Cambridge      2 Maintenenace\n## 3 Moe        Wallace        3 Electrical  \n## 4 Joe        Frasier        4 Manager\nSQL queries can be powerful, and they can also get huge if you have to join multiple tables. This introduction does not go in depth, so to learn more you should do some research. If you know R, you will see some parallels between the dplyr package and SQL queries. In fact, R actually supports SQL to get data straight from central relational databases. In this introductory tutorial, databases were introduced, basic examples were given for each of the three SQL languages, and some queries were shown in the R programming language.\n\nJoseph Shifman is a Computer Science major with a minor in Math. He is also in the Data Science Certificate program at CSU Chico. To see more projects he has worked on, check out his Github or his LinkedIn."
  },
  {
    "objectID": "posts/2022-10-27-fooling-facial-recognition/index.en.html",
    "href": "posts/2022-10-27-fooling-facial-recognition/index.en.html",
    "title": "Fooling Facial Recognition",
    "section": "",
    "text": "Most people have seen deep fakes and AI generated images online but people often don’t know the underlying technology behind it. For my senior Capstone, I am conducting a research project which uses Adversarial Networks and found this to be a very cool realm of machine learning.\n\nThe basic design of a Adversarial system include two different networks, the generator and the discriminator. The Generator will simply take in a random seed as an input and use that number to calculate pixel values. The Discriminator will be paired with a training set which is a mix of real images and generated images. It will then train over this set and classify them as either real or fake. Both networks will then be trained on the accuracy of the discriminator but in opposite directions. While the discriminator will try to maximize it’s accuracy, the generator will try to minimize it by generating images that the discriminator will think its real. This process has been used and has produce some facinating results in the machine learning sphere."
  },
  {
    "objectID": "posts/2022-10-27-fooling-facial-recognition/index.en.html#tidy-models-tutorial",
    "href": "posts/2022-10-27-fooling-facial-recognition/index.en.html#tidy-models-tutorial",
    "title": "Fooling Facial Recognition",
    "section": "Tidy Models Tutorial",
    "text": "Tidy Models Tutorial\nIn this tutorial I will walk you through how to fit a linear model to a data set using the tidy models package. In this tutorial I will be using a CalCOFI data set of oceanic measurements of temperature in Celsius and depth in Meters. Here we will see what the relationship between temperature and depth shallower than 500 meters.\n\nLibraries\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(readr)\n\n\nStep 1 - Import and Setup Dataset\nOur first step will be to import CalCOFI data and filter for our desired depth, done by the R code below.\n#Base Dataset\nCalCOFI <- read.csv(\"CalCOFI.csv\")\n\n# Depth lower than 500 filtered out\nCalCOFI <- CalCOFI %>%\nfilter(Depthm < 500)\n\n\nStep 2 - Initial Visualization\nBefore we begin modeling, we will want to see if linear modeling is applicable in this case. We can do this by some data visualization with a linear trend line, done by the R code below.\nCalCOFI %>%\nggplot(aes(Depthm, T_degC)) + geom_point() + geom_smooth(method = \"lm\", se = FALSE)\n\nBased on the graph above, the fit can be roughly described as linear and makes linear regression applicable.\n\n\nStep 3 - Build and Fit Model\nNow we can Build and fit out model to our data, done by the R code below.\n# Build\nmodel <- linear_reg() %>%\n  set_engine(\"lm\")\n\n# Fit\nfit <- model %>%\n  fit(T_degC~Depthm, data = CalCOFI)\n\n\nStep 4 - Interpretation\nOur last step is to interpret the model we have fit. So to view our coefficients, see R code below.\ntidy(fit)\n## # A tibble: 2 × 5\n##   term        estimate std.error statistic p.value\n##   <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n## 1 (Intercept)  15.0    0.00415       3609.       0\n## 2 Depthm       -0.0239 0.0000225    -1065.       0\nFrom this we can see an association of depth to temperature of -0.0239. This means that on average, for every single meter increase of depth would result a decrease in temperature of 0.0239 Celsius."
  },
  {
    "objectID": "posts/2022-10-27-fooling-facial-recognition/index.en.html#fooling-facial-recognition-software-using-convoltional-generative-adversarial-networks",
    "href": "posts/2022-10-27-fooling-facial-recognition/index.en.html#fooling-facial-recognition-software-using-convoltional-generative-adversarial-networks",
    "title": "Fooling Facial Recognition",
    "section": "Fooling Facial Recognition Software Using Convoltional Generative Adversarial Networks",
    "text": "Fooling Facial Recognition Software Using Convoltional Generative Adversarial Networks\n\nBackground\nFacial Recognition software is becoming more and more prevalent in our daily lives from our phones to law enforcement. To help prevent the misuse of this kind of software we should further our understanding of these algorithms so they don’t remain as mysterious black boxes. This project’s goal was to test the accuracy of open-source pre-trained Facial Recognition models using Deep Convolutional Generative Adversarial Networks or DCGANs. The DCGAN was used to generate images from random noise which would then be scored based on what confidence score it can elicit from pre-existing facial recognition models for a specific person’s Identity (such as The Rock). This project focuses on generating images that are identified as one of four recognized Identities by the recognition model. The generated test images that had a high confidence score of being a recognized image were subsequently looked at by humans to see if they looked like their classified identities. This will give us insight on how an end user can create fake generated images and still elicit high confidence scores from facial recognition software.\n\n\nExperiment Overview\n\n\nNoise:\n\nnormally distributed random numbers\n\n\n\nGenerator: Deep Convolutional Generator\nInput Layer:\n\n100 values Hidden Layers:\nFully Connected\nTransposed Convolution A.K.A Deconvolution\nActivation Function: LeakyReLU\n\nOutput Layer:\n\n224 x 224 pixels\nActivation Function: Sigmoid\n\n\n\nFacial Recognition Model\nVGGFace2 Models implemented in Keras\n\nInput preprocessing\nConvolutional Architectures\nResNet50 and SENet50\n\nOutput:\n\nConfidences on 8631 Identities\n\n\n\nTraining the Generator\nSetup in Jupyter using Python\n\nEach Generator focuses on 1 Identity\nBatch size of 5\nLoss based on how high a confidence the Recognition Model outputs\nLoss Calculated using Cross Entropy\nExponentially Decaying Learning Rate\n\n\n\nGPU:\n\nNVIDIA GeForce GTX 1660 Ti with Max-Q Design\n\n\n\n\nResults\n\nReal Face Controls\n\n\n\nGenerated Images\n\n\n\n\nConclusion\nThe results of this project show that it is possible to train a Generator for each Identity in the VGGFace2 and achieve a high confidence score. This method is still contingent on having access to the full model. This indicates that open source models such as these can be fooled by potentially malicious actors while other closed-source models may remain safe, but more research would be advised. Future research would best be targeted at replication using smaller generators, testing other learning rates and loss functions, testing this method for Facial Detectors since they are often paired with Facial Recognition, and using this method to improve model accuracy through training with generated false images."
  },
  {
    "objectID": "posts/2022-11-27-bls-open-pos/index.en.html",
    "href": "posts/2022-11-27-bls-open-pos/index.en.html",
    "title": "Research Statistician vacancies at the Bureau of Labor Statistics",
    "section": "",
    "text": "This is a cross-post from a recent Project-DAFANH “Ask me anything” career speaker.\n\nDo you enjoy conducting statistical or survey methodological research? Would you like to join a group of researchers and be on the forefront of developing novel statistical methodologies that directly impact federal economic indicators? Does a federal job that emphasizes work-life balance and is committed to your professional development sound right for you?\nhttps://www.usajobs.gov/job/688034000\nThen consider applying to the Bureau of Labor Statistics (BLS) Office of Survey Methods Research! We’re hiring GS-12 or GS-13 Research Mathematical Statisticians to join the Mathematical Statistics Research Center, where we strive to improve the accuracy of BLS survey data and the estimates BLS publishes, where we aim to improve the efficiency of BLS data collection and estimation methods, and where we get to consult with economists, statisticians, and data scientists on emerging mathematical statistical issues to support all of BLS!\nTo apply for this position, please go to USAJobs: https://www.usajobs.gov/job/688034000. For more information about this posting, contact Jeff Gonzalez (Gonzalez.Jeffrey@bls.gov).\nTips for a successful application process:\n\nProvide transcripts that document the degree requirements listed in the Qualifications section of the announcement. If you think the transcripts are not self-explanatory, you can add a section for “relevant coursework” to the education section of your resume or CV highlighting the courses and credits that should count toward the requirement. Provide all relevant transcripts, not just your most recent one.\nTailor your resume or CV to this vacancy announcement. Document your relevant work experience through bullet points in your resume or CV. Reflect the language used in the announcement where applicable (see Duties and Specialized Experience under Qualifications). For example, identify your methodological research, convey that it contributed to new or improved methods, and include how you disseminated your research findings. Resumes are first reviewed by non-technical human resources staff that determine whether you are minimally qualified by ensuring your resume corresponds to the requirements listed in the announcement.\nYour work experience bullet points should be tied to positions for which you list start and stop dates, using “MM/YYYY” format, for employment as well as hour-per-week. This is how human resources staff determine whether your cumulative experience meets the work threshold (see Specialized Experience under Qualifications).\nYou do not have to limit your resume or CV to one or two pages. You can take as much room as you need (within reason) to convey your qualifications but be sure to proofread it before you submit your application.\nFor more information on writing an effective Federal resume, read: Tips for Writing a Federal Resume | U.S. Department of Labor (dol.gov)"
  },
  {
    "objectID": "posts/2022-11-27-tech-justice/index.en.html",
    "href": "posts/2022-11-27-tech-justice/index.en.html",
    "title": "Exploring Tech Justice: The Just Data Lab",
    "section": "",
    "text": "As part of the Advanced Data Science, we explored how technology can perpetuate existing structures of discrimination through its design and application. As a part of this exploration, we read Race After Technology by Ruha Benjamin. As a person who may use data and algorithms to make decisions in the future it is important for me to understand how others experience these algorithims, and what should be done in light of the role technology. In this blog post I will introduce what the Just Data Lab and how they are leveraging data and technology for justice"
  },
  {
    "objectID": "posts/2022-11-27-tech-justice/index.en.html#what-is-the-just-data-lab",
    "href": "posts/2022-11-27-tech-justice/index.en.html#what-is-the-just-data-lab",
    "title": "Exploring Tech Justice: The Just Data Lab",
    "section": "What is the Just Data Lab?",
    "text": "What is the Just Data Lab?\nAuthor of Race After Technology, Ruha Benjamin, founded the Ida B. Wells Just Data Lab at Princeton. The lab was named after late 19th and early 20th centuries prominent journalist, activist, and researcher Ida B. Wells. Click here for a brief biography of Ida B. Wells. The goal of the lab is to “rethink and retool data for justice”. The lab addresses a variety of issues from revealing companies engaged in immigrant surveillance to developing strategies to aid formerly incarcerated small business owners. Additionally, the lab has a variety of tech and social justice initiatives. The lab has lots of cool projects! The Barred Business Project provides business grants to support the work of formerly incarcerated Black, Transgender, Queer, Native, and Disabled business owners. In order to further enhance the mission to help these groups, the team leveraged data to tell stories by creating an interactive map. Here you can see the map. They also provide a list of resources for community engagement. One I found particularly interesting was the Equitable Internet Initiative. This initiative seeks to increase internet access in underserved Detroit neighborhoods. One of the reasons I found this initiative particularly interesting was the emphasis on community engagement. The majority of the workers come from the neighborhoods they work in. This is just one of the initiatives the lab is a part of."
  },
  {
    "objectID": "posts/2022-11-27-tech-justice/index.en.html#how-can-people-get-involved-in-this-organization",
    "href": "posts/2022-11-27-tech-justice/index.en.html#how-can-people-get-involved-in-this-organization",
    "title": "Exploring Tech Justice: The Just Data Lab",
    "section": "How can people get involved in this organization?",
    "text": "How can people get involved in this organization?\nCheckout the Just Data Lab’s website. Here, the teams have worked hard, using the data and explaining the situation of many groups who are under-represented and may have different experiences than you. Go to their website and read up on some of the work they have done. This link will also show you more about other organizations that may be in the area or have options to get involved for those out of the area. (Note: You may have to scroll down for the page to load.) Educating yourself is another way to get involved. If you are interested in learning more about data ethic read Race After Technology and/or follow the author of Race After Technology and founder of the Just Data Lab, Ruha Benjamin on Twitter.\nIf you want to take it a step further and are a part of a community-based organization focused on social justice you can apply to partner with the lab! This is an incredible opportunity to access the resources of the lab to enhance your organization. Checkout the logistics of applying here!"
  },
  {
    "objectID": "posts/2022-11-27-tech-justice/index.en.html#what-is-a-tech-justice-issue-in-your-own-community-that-you-and-your-neighbors-could-address",
    "href": "posts/2022-11-27-tech-justice/index.en.html#what-is-a-tech-justice-issue-in-your-own-community-that-you-and-your-neighbors-could-address",
    "title": "Exploring Tech Justice: The Just Data Lab",
    "section": "What is a tech justice issue in your own community that you and your neighbors could address?",
    "text": "What is a tech justice issue in your own community that you and your neighbors could address?\nOne potential tech justice issue that could be addressed in the community, Chico State’s Campus, is mapping surveillance. The lab accentuates mapping due to the ease of understanding. There are likely surveillance technologies used in the community many are unaware of. To address this we could research the surveillance technologies used in our community. Then this information could be used to create a map for public use. It is important that the community is aware of the surveillance and the usage of the surveillance.\n\nAuthor Bio\nMy name is Faith, and I’m a Chico State graduate. I majored in mathematics and economics. I am interested in harnessing the power of mathematics to study real world problems. Checkout my linkedin profile!"
  },
  {
    "objectID": "posts/2023-03-03-datafest-2023-registration-now-open/index.en.html#what-is-the-asa-datafest",
    "href": "posts/2023-03-03-datafest-2023-registration-now-open/index.en.html#what-is-the-asa-datafest",
    "title": "DataFest 2023 April 14-16- Registration now open!",
    "section": "What is the ASA DataFest?",
    "text": "What is the ASA DataFest?\nASA DataFest is a data hackathon for undergraduate students, sponsored by the American Statistical Association and founded at UCLA, in 2011. A data analysis problem is presented in the form of a dataset and an associated challenge. Teams of students get a dataset on Friday afternoon and work on the problem until Sunday afternoon where they present their findings. After two days of intense data wrangling, analysis, and presentation design, each team is allowed a few minutes and no more than two slides to impress a panel of judges. Prizes are given for Best in Show, Best Visualization, and Best Use of External Data.\nUndergraduates from all majors are welcome. Some of the most diverse teams have been the most successful.\nThis event is open to ALL undergraduates in the North State!"
  },
  {
    "objectID": "posts/2023-03-03-datafest-2023-registration-now-open/index.en.html#at-sacramento-state",
    "href": "posts/2023-03-03-datafest-2023-registration-now-open/index.en.html#at-sacramento-state",
    "title": "DataFest 2023 April 14-16- Registration now open!",
    "section": "At Sacramento State",
    "text": "At Sacramento State\nThis time we’re heading down south and joining our colleagues at Sacramento State\nLearn more about this national event at the event website: https://norcaldatafest.netlify.app/"
  },
  {
    "objectID": "posts/2023-03-09-health-equity-datathon/index.en.html",
    "href": "posts/2023-03-09-health-equity-datathon/index.en.html",
    "title": "Health Equity Datathon",
    "section": "",
    "text": "To learn more and secure your spot >> CIVIC-HACKERS.ORG/HED23"
  }
]